{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d596de28",
      "metadata": {},
      "source": [
        "# GroundedDINO + SAM — Detection (Colab Pro+) — commit ef4284f\n",
        "Детектор регионов: монтируем GCS (через сервис‑аккаунт), ставим Torch+детекторы, рендерим страницы, запускаем детекцию и грузим регионы в `gs://pik-artifacts-dev/grounded_regions/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91d7fd2",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Runtime & GPU\n",
        "NOTEBOOK_VERSION = 'ef4284f'\n",
        "print('Notebook version:', NOTEBOOK_VERSION)\n",
        "# Runtime & GPU\n",
        "!nvidia-smi || true\n",
        "import sys; print(sys.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd390ea",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Auth + gcsfuse setup\n",
        "# Install packages and prepare gcsfuse repo; auto-mount with SA from /content/Secrets if present\n",
        "# Try Colab user auth (optional)\n",
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print('[auth] Colab user credentials OK')\n",
        "except Exception as e:\n",
        "  print('[auth] Skipping Colab user auth:', e)\n",
        "!pip -q install google-cloud-storage gcsfs\n",
        "!sudo install -m 0755 -d /usr/share/keyrings\n",
        "!curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg -o /tmp/cloud.google.gpg\n",
        "!sudo gpg --dearmor --yes --batch -o /usr/share/keyrings/cloud.google.gpg /tmp/cloud.google.gpg || sudo cp /tmp/cloud.google.gpg /usr/share/keyrings/cloud.google.gpg\n",
        "!echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt gcsfuse-jammy main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list >/dev/null\n",
        "!sudo apt-get -q update\n",
        "!sudo apt-get -q install -y gcsfuse poppler-utils\n",
        "!mkdir -p /content/src_gcs /content/artifacts /content/pages /content/Secrets\n",
        "import glob, os, subprocess, shlex\n",
        "\n",
        "# Read SA key from Colab Secrets (GCS_SA_JSON or secretName) and persist to /content/Secrets/sa.json\n",
        "try:\n",
        "  from google.colab import userdata as _ud\n",
        "  _sa = _ud.get('GCS_SA_JSON') or _ud.get('secretName')\n",
        "except Exception:\n",
        "  _sa = None\n",
        "if _sa:\n",
        "  os.makedirs('/content/Secrets', exist_ok=True)\n",
        "  _key_path = '/content/Secrets/sa.json'\n",
        "  open(_key_path,'w',encoding='utf-8').write(_sa)\n",
        "  os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = _key_path\n",
        "  print('[auth] SA key written to', _key_path)\n",
        "\n",
        "matches = glob.glob('/content/Secrets/*.json')\n",
        "if matches:\n",
        "  KEY = matches[0]\n",
        "  os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = KEY\n",
        "  print('Found SA key:', KEY)\n",
        "  subprocess.run(shlex.split('fusermount -u /content/src_gcs'), check=False)\n",
        "  subprocess.run(shlex.split('fusermount -u /content/artifacts'), check=False)\n",
        "  code1 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik_source_bucket','/content/src_gcs']).returncode\n",
        "  code2 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik-artifacts-dev','/content/artifacts']).returncode\n",
        "  print('mount src=', code1==0, ' mount artifacts=', code2==0)\n",
        "else:\n",
        "  # Ручная загрузка ключа (как раньше)\n",
        "  from google.colab import files\n",
        "  print('Загрузите JSON-ключ сервис-аккаунта (sa.json)')\n",
        "  uploaded = files.upload()\n",
        "  if uploaded:\n",
        "    KEY = '/content/' + list(uploaded.keys())[0]\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = KEY\n",
        "    subprocess.run(shlex.split('fusermount -u /content/src_gcs'), check=False)\n",
        "    subprocess.run(shlex.split('fusermount -u /content/artifacts'), check=False)\n",
        "    c1 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik_source_bucket','/content/src_gcs']).returncode\n",
        "    c2 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik-artifacts-dev','/content/artifacts']).returncode\n",
        "    print('mount src=', c1==0, ' mount artifacts=', c2==0)\n",
        "  else:\n",
        "    KEY = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9813e96",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Mount GCS buckets\n",
        "# Robust mount with verbose logs and fallback info\n",
        "import os, glob, subprocess, pathlib, textwrap\n",
        "pathlib.Path('/content/src_gcs').mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path('/content/artifacts').mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path('/content/gcsfuse_tmp').mkdir(parents=True, exist_ok=True)\n",
        "key = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '')\n",
        "if (not key) and 'KEY' in globals(): key = KEY\n",
        "if key and not os.path.isabs(key): key = os.path.join('/content', key)\n",
        "if not (key and os.path.exists(key)):\n",
        "  matches = glob.glob('/content/Secrets/*.json')\n",
        "  if matches:\n",
        "    key = matches[0]; os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key\n",
        "  else:\n",
        "    raise SystemExit('Service account key not found — upload to /content/Secrets/*.json')\n",
        "print('Using SA key:', key)\n",
        "def mount(bucket, mnt):\n",
        "  log=f'/content/gcsfuse_{bucket}.log'.replace('/', '_')\n",
        "  cmd=['gcsfuse','--implicit-dirs','--key-file', key,'--temp-dir','/content/gcsfuse_tmp','--log-file',log, bucket, mnt]\n",
        "  res=subprocess.run(cmd, capture_output=True, text=True)\n",
        "  ok=(res.returncode==0)\n",
        "  print(f'[mount] {bucket} -> {mnt}:', ok)\n",
        "  if not ok:\n",
        "    print('[mount] stdout:\\n' + res.stdout)\n",
        "    print('[mount] stderr:\\n' + res.stderr)\n",
        "    try:\n",
        "      tail=subprocess.run(['bash','-lc', f'tail -n 80 {log}'], capture_output=True, text=True)\n",
        "      if tail.stdout: print('[mount] log tail:\\n' + tail.stdout)\n",
        "    except Exception: pass\n",
        "  return ok\n",
        "subprocess.run(['fusermount','-u','/content/src_gcs'], check=False)\n",
        "subprocess.run(['fusermount','-u','/content/artifacts'], check=False)\n",
        "# Quick bucket existence check\n",
        "for b in ('pik_source_bucket','pik-artifacts-dev'):\n",
        "  subprocess.run(['bash','-lc', f'gsutil ls -b gs://{b} || true'], check=False)\n",
        "ok1 = mount('pik_source_bucket','/content/src_gcs')\n",
        "ok2 = mount('pik-artifacts-dev','/content/artifacts')\n",
        "print('mount src=', ok1, ' mount artifacts=', ok2)\n",
        "if not (ok1 and ok2):\n",
        "  print(textwrap.dedent('''\n    [hint] If mount keeps failing:\n      - Check SA has Storage Object Admin on both buckets\n      - Try fallback: copy files with gsutil (already used elsewhere in the notebook)\n      - Ensure bucket names are correct and exist (see checks above)\n    '''))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6309994d",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install Torch + SAM/SAM2 + GroundedDINO\n",
        "# 2) Torch + детекторы — надёжная установка (без сборки wheel для GroundedDINO)\n",
        "!pip -q install --upgrade pip setuptools wheel\n",
        "# Ensure IPython+jedi present to avoid resolver warning\n",
        "!pip -q install --upgrade 'ipython>=8' 'jedi>=0.18.2'\n",
        "!pip -q install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install shapely timm opencv-python pycocotools addict yacs requests pillow\n",
        "!pip -q install huggingface_hub\n",
        "!pip -q install xformers==0.0.27.post2 || echo 'xformers wheel not available; skipping'\n",
        "# SAM\n",
        "!pip -q install git+https://github.com/facebookresearch/segment-anything.git\n",
        "# SAM2\n",
        "!pip -q install git+https://github.com/facebookresearch/segment-anything-2.git\n",
        "# GroundedDINO из исходников (подключим через sys.path)\n",
        "!rm -rf /content/GroundingDINO\n",
        "!git clone --depth 1 https://github.com/IDEA-Research/GroundingDINO.git /content/GroundingDINO\n",
        "!pip -q install -r /content/GroundingDINO/requirements.txt\n",
        "# Build C++/CUDA ops for GroundingDINO (ms_deform_attn _C)\n",
        "!sudo apt-get -q install -y ninja-build\n",
        "!pip -q install \"git+https://github.com/IDEA-Research/GroundingDINO.git\" || echo 'pip install from git failed; will import from source'\n",
        "import sys, os, glob, subprocess\n",
        "try:\n",
        "  import groundingdino\n",
        "  print('GroundingDINO pip install OK')\n",
        "except Exception as e:\n",
        "  print('GroundingDINO pip install failed; building from source:', e)\n",
        "  cands = [p for p in glob.glob('/content/GroundingDINO/**/setup.py', recursive=True) if ('ms_deform' in p) or ('ops' in p)]\n",
        "  for sp in cands:\n",
        "    d=os.path.dirname(sp); print('Building ext in', d)\n",
        "    subprocess.run([sys.executable, 'setup.py', 'build_ext', '--inplace'], cwd=d, check=False)\n",
        "  if '/content/GroundingDINO' not in sys.path: sys.path.append('/content/GroundingDINO')\n",
        "  import groundingdino\n",
        "  print('GroundingDINO import OK (source fallback)')\n",
        "# Build C++/CUDA ops for GroundingDINO (ms_deform_attn _C)\n",
        "import sys\n",
        "if '/content/GroundingDINO' not in sys.path: sys.path.append('/content/GroundingDINO')\n",
        "from groundingdino.util.inference import Model\n",
        "print('GroundedDINO import OK')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3faa9ae",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CUDA and C++ ops self-check\n",
        "import warnings, importlib, torch, torchvision, os\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "req = (DEVICE.lower() if 'DEVICE' in globals() else 'auto')\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "print('torch:', torch.__version__, 'cuda:', torch.version.cuda, 'available:', cuda_avail)\n",
        "print('torchvision:', torchvision.__version__)\n",
        "tv_ops_ok=False\n",
        "if cuda_avail:\n",
        "  try:\n",
        "    x=torch.rand(256,4,device='cuda'); y=torch.rand(256,4,device='cuda')\n",
        "    from torchvision.ops import box_iou\n",
        "    _=box_iou(x,y); tv_ops_ok=True; print('[OK] torchvision.ops on CUDA')\n",
        "  except Exception as e:\n",
        "    print('[WARN] torchvision.ops CUDA failed:', e)\n",
        "try:\n",
        "  m=importlib.import_module('groundingdino.models.GroundingDINO.ms_deform_attn')\n",
        "  dino_ops_ok=bool(getattr(m,'_C', None))\n",
        "  print('GroundingDINO _C present:', dino_ops_ok)\n",
        "except Exception as e:\n",
        "  dino_ops_ok=False; print('[WARN] GroundingDINO C++ ops import failed:', e)\n",
        "# Hard assertions when DEVICE='cuda'\n",
        "if req=='cuda':\n",
        "  assert cuda_avail, 'CUDA requested but not available'\n",
        "  assert tv_ops_ok, 'torchvision CUDA ops unavailable'\n",
        "  assert dino_ops_ok, 'GroundingDINO C++ ops (_C) not built'\n",
        "print('[SELF-CHECK] req=', req, ' cuda_avail=', cuda_avail, ' tv_ops_ok=', tv_ops_ok, ' dino_ops_ok=', dino_ops_ok)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d75b85",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download/Resolve Model Weights\n",
        "#@title Download/Resolve Model Weights\n",
        "# (Optional) Download model weights if not present\n",
        "import os, pathlib, shutil, subprocess\n",
        "from typing import Optional\n",
        "pathlib.Path('/content/models/groundingdino').mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path('/content/models/sam').mkdir(parents=True, exist_ok=True)\n",
        "GROUNDING_MODEL = '/content/models/groundingdino/groundingdino_swint_ogc.pth'\n",
        "SAM_MODEL = '/content/models/sam/sam_vit_h_4b8939.pth'\n",
        "GROUNDING_URL = 'https://github.com/IDEA-Research/GroundingDINO/releases/download/0.1.0/groundingdino_swint_ogc.pth'\n",
        "SAM_URL = 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
        "SAM2_MODEL = '/content/models/sam2/sam2_hiera_large.pt'\n",
        "SAM2_URL = 'https://huggingface.co/facebook/sam2-hiera-large/resolve/main/sam2_hiera_large.pt'\n",
        "# Try to read HF token from Colab Keys or env\n",
        "HF_TOKEN = os.getenv('HF_TOKEN', '')\n",
        "try:\n",
        "  from google.colab import userdata as _ud\n",
        "  HF_TOKEN = _ud.get('HF_TOKEN') or HF_TOKEN\n",
        "except Exception:\n",
        "  pass\n",
        "def _file_ok(p: str, min_size: int) -> bool:\n",
        "  try:\n",
        "    return os.path.exists(p) and os.path.getsize(p) >= min_size\n",
        "  except Exception:\n",
        "    return False\n",
        "def _try_torch_load(p: str) -> bool:\n",
        "  try:\n",
        "    import torch\n",
        "    torch.load(p, map_location='cpu')\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    print('[warn] torch.load failed:', e)\n",
        "    return False\n",
        "def _hf_download(repo_id: str, filename: str, dest: str) -> bool:\n",
        "  try:\n",
        "    from huggingface_hub import hf_hub_download, login\n",
        "    if HF_TOKEN:\n",
        "      try:\n",
        "        login(token=HF_TOKEN)\n",
        "      except Exception as e:\n",
        "        print('[warn] HF login failed:', e)\n",
        "    ckpt = hf_hub_download(repo_id=repo_id, filename=filename, local_dir=os.path.dirname(dest), local_dir_use_symlinks=False, token=HF_TOKEN or None)\n",
        "    if ckpt != dest:\n",
        "      shutil.copy2(ckpt, dest)\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    print('[warn] HF download failed:', e)\n",
        "    return False\n",
        "def _curl(url: str, dest: str, min_size: int) -> bool:\n",
        "  cmd = f\"curl -L --fail --retry 5 --retry-all-errors -o '{dest}.tmp' '{url}'\"\n",
        "  rc = subprocess.call(cmd, shell=True)\n",
        "  if rc == 0 and _file_ok(dest + '.tmp', min_size):\n",
        "    shutil.move(dest + '.tmp', dest)\n",
        "    return True\n",
        "  else:\n",
        "    print('[warn] curl download insufficient or failed:', rc)\n",
        "    try:\n",
        "      os.remove(dest + '.tmp')\n",
        "    except Exception:\n",
        "      pass\n",
        "    return False\n",
        "# GroundedDINO (expect ~0.9GB)\n",
        "MIN_DINO = 600_000_000\n",
        "need_dino = (not _file_ok(GROUNDING_MODEL, MIN_DINO)) or (not _try_torch_load(GROUNDING_MODEL))\n",
        "if need_dino:\n",
        "  print('Downloading GroundingDINO weights (robust)...')\n",
        "  try:\n",
        "    os.remove(GROUNDING_MODEL)\n",
        "  except Exception:\n",
        "    pass\n",
        "  # 1) Try GCS mirror if mounted\n",
        "  gcs_mirror = '/content/artifacts/models/groundingdino/groundingdino_swint_ogc.pth'\n",
        "  ok = _file_ok(gcs_mirror, MIN_DINO)\n",
        "  if ok:\n",
        "    try:\n",
        "      shutil.copy2(gcs_mirror, GROUNDING_MODEL)\n",
        "      print('[DINO] using GCS mirror')\n",
        "      ok = True\n",
        "    except Exception as e:\n",
        "      print('[warn] copy from GCS mirror failed:', e); ok = False\n",
        "  # 2) Try HF Hub (public repo)\n",
        "  if (not ok):\n",
        "    ok = _hf_download('ShilongLiu/GroundingDINO', 'groundingdino_swint_ogc.pth', GROUNDING_MODEL)\n",
        "    if ok: print('[DINO] using HF Hub')\n",
        "  # 3) Try GitHub release via curl\n",
        "  if (not ok) or (not _file_ok(GROUNDING_MODEL, MIN_DINO)):\n",
        "    ok = _curl(GROUNDING_URL, GROUNDING_MODEL, MIN_DINO)\n",
        "    if ok: print('[DINO] using curl URL')\n",
        "  # 4) Try gsutil from bucket path if accessible\n",
        "  if (not ok) or (not _file_ok(GROUNDING_MODEL, MIN_DINO)):\n",
        "    try:\n",
        "      rc = subprocess.call(f\"gsutil cp gs://pik-artifacts-dev/models/groundingdino/groundingdino_swint_ogc.pth '{GROUNDING_MODEL}'\", shell=True)\n",
        "      ok = (rc == 0) and _file_ok(GROUNDING_MODEL, MIN_DINO)\n",
        "      if ok: print('[DINO] using gsutil mirror')\n",
        "    except Exception as e:\n",
        "      print('[warn] gsutil mirror copy failed:', e)\n",
        "  if (not ok) or (not _file_ok(GROUNDING_MODEL, MIN_DINO)) or (not _try_torch_load(GROUNDING_MODEL)):\n",
        "    raise SystemExit('Failed to fetch a valid GroundingDINO checkpoint')\n",
        "# SAM (ViT-H is large; check size only)\n",
        "MIN_SAM = 1_000_000_000\n",
        "if not _file_ok(SAM_MODEL, MIN_SAM):\n",
        "  print('Downloading SAM ViT-H weights (robust)...')\n",
        "  # 1) Try GCS mirror if mounted\n",
        "  sam_gcs_mirror = '/content/artifacts/models/sam/sam_vit_h_4b8939.pth'\n",
        "  ok = _file_ok(sam_gcs_mirror, MIN_SAM)\n",
        "  if ok:\n",
        "    try:\n",
        "      shutil.copy2(sam_gcs_mirror, SAM_MODEL)\n",
        "      print('[SAM] using GCS mirror')\n",
        "      ok = True\n",
        "    except Exception as e:\n",
        "      print('[warn] copy SAM from GCS mirror failed:', e); ok = False\n",
        "  # 2) Try HF Hub\n",
        "  if (not ok):\n",
        "    ok = _hf_download('facebook/sam', 'sam_vit_h_4b8939.pth', SAM_MODEL)\n",
        "    if ok: print('[SAM] using HF Hub')\n",
        "  # 3) Try official URL via curl\n",
        "  if (not ok) or (not _file_ok(SAM_MODEL, MIN_SAM)):\n",
        "    ok = _curl(SAM_URL, SAM_MODEL, MIN_SAM)\n",
        "    if ok: print('[SAM] using curl URL')\n",
        "  # 4) Try gsutil mirror from bucket\n",
        "  if (not ok) or (not _file_ok(SAM_MODEL, MIN_SAM)):\n",
        "    try:\n",
        "      rc = subprocess.call(f\"gsutil cp gs://pik-artifacts-dev/models/sam/sam_vit_h_4b8939.pth '{SAM_MODEL}'\", shell=True)\n",
        "      ok = (rc == 0) and _file_ok(SAM_MODEL, MIN_SAM)\n",
        "      if ok: print('[SAM] using gsutil mirror')\n",
        "    except Exception as e:\n",
        "      print('[warn] gsutil SAM mirror copy failed:', e)\n",
        "  if (not ok) or (not _file_ok(SAM_MODEL, MIN_SAM)):\n",
        "    raise SystemExit('Failed to fetch SAM ViT-H checkpoint')\n",
        "# SAM2 (Hiera Large)\n",
        "MIN_SAM2 = 700_000_000\n",
        "if not _file_ok(SAM2_MODEL, MIN_SAM2):\n",
        "  print('Downloading SAM2 Hiera Large weights (robust)...')\n",
        "  # 1) Try GCS mirror if mounted\n",
        "  sam2_gcs_mirror = '/content/artifacts/models/sam2/sam2_hiera_large.pt'\n",
        "  ok = _file_ok(sam2_gcs_mirror, MIN_SAM2)\n",
        "  if ok:\n",
        "    try:\n",
        "      shutil.copy2(sam2_gcs_mirror, SAM2_MODEL)\n",
        "      print('[SAM2] using GCS mirror')\n",
        "      ok = True\n",
        "    except Exception as e:\n",
        "      print('[warn] copy SAM2 from GCS mirror failed:', e); ok = False\n",
        "  # 2) Try HF Hub\n",
        "  if (not ok):\n",
        "    ok = _hf_download('facebook/sam2-hiera-large', 'sam2_hiera_large.pt', SAM2_MODEL)\n",
        "    if ok: print('[SAM2] using HF Hub')\n",
        "  # 3) Try direct URL via curl\n",
        "  if (not ok) or (not _file_ok(SAM2_MODEL, MIN_SAM2)):\n",
        "    ok = _curl(SAM2_URL, SAM2_MODEL, MIN_SAM2)\n",
        "    if ok: print('[SAM2] using curl URL')\n",
        "  # 4) Try gsutil mirror from bucket\n",
        "  if (not ok) or (not _file_ok(SAM2_MODEL, MIN_SAM2)):\n",
        "    try:\n",
        "      rc = subprocess.call(f\"gsutil cp gs://pik-artifacts-dev/models/sam2/sam2_hiera_large.pt '{SAM2_MODEL}'\", shell=True)\n",
        "      ok = (rc == 0) and _file_ok(SAM2_MODEL, MIN_SAM2)\n",
        "      if ok: print('[SAM2] using gsutil mirror')\n",
        "    except Exception as e:\n",
        "      print('[warn] gsutil SAM2 mirror copy failed:', e)\n",
        "  if (not ok) or (not _file_ok(SAM2_MODEL, MIN_SAM2)):\n",
        "    raise SystemExit('Failed to fetch SAM2 Hiera Large checkpoint')\n",
        "import os as _os; print('[DINO] size=', _os.path.getsize(GROUNDING_MODEL)); print('GROUNDING_MODEL =', GROUNDING_MODEL)\n",
        "import os as _os; print('[SAM2] size=', _os.path.getsize(SAM2_MODEL))\n",
        "import os as _os; print('[SAM] size=', _os.path.getsize(SAM_MODEL)); print('SAM_MODEL       =', SAM_MODEL)\n",
        "\n",
        "# Log weights info if logging enabled\n",
        "try:\n",
        "  import os as _os\n",
        "  WEIGHTS_INFO = {\n",
        "    'groundingdino': {'path': GROUNDING_MODEL, 'size': _os.path.getsize(GROUNDING_MODEL)},\n",
        "    'sam': {'path': SAM_MODEL, 'size': _os.path.getsize(SAM_MODEL)},\n",
        "    'sam2': ({'path': SAM2_MODEL, 'size': _os.path.getsize(SAM2_MODEL)} if _os.path.exists(SAM2_MODEL) else None),\n",
        "  }\n",
        "  if 'log_json' in globals(): log_json('weights.json', WEIGHTS_INFO)\n",
        "except Exception as e:\n",
        "  print('[LOG] weights info not recorded:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56041eff",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Detection Parameters\n",
        "PLAYBOOK_PDF = '/content/src_gcs/playbooks/PIK - Expert Guide - Platform IT Architecture - Playbook - v11.pdf'  #@param {type:\"string\"}\n",
        "PAGES = [4,5,6,7,8,9,10,11]  #@param {type:\"raw\"}\n",
        "FRAME_NAMES_INPUT = 'PIK - Platform IT Architecture Canvas - Table View - v01.png, PIK - Platform IT Architecture Canvases - v01.png, PIK - Expert Guide - Platform IT Architecture - Assessment - v01.png'  #@param {type:\"string\"}\n",
        "PROMPTS_INPUT = 'diagram,canvas,table,legend,arrow,node'  #@param {type:\"string\"}\n",
        "BOX_THRESHOLD = 0.35  #@param {type:\"number\"}\n",
        "TEXT_THRESHOLD = 0.25  #@param {type:\"number\"}\n",
        "TOPK = 12  #@param {type:\"integer\"}\n",
        "DEVICE = 'auto'  #@param [\"auto\", \"cuda\", \"cpu\"]\n",
        "USE_SAM2 = True  #@param {type:\"boolean\"}\n",
        "\n",
        "REPORT_TO_GCS = True  #@param {type:\"boolean\"}\n",
        "GCS_BUCKET = 'pik-artifacts-dev'  #@param {type:\"string\"}\n",
        "RUN_TAG = ''  #@param {type:\"string\"}\n",
        "\n",
        "# Derived lists from string inputs\n",
        "FRAME_NAMES = [x.strip() for x in FRAME_NAMES_INPUT.split(',') if x.strip()]\n",
        "PROMPTS = [x.strip() for x in PROMPTS_INPUT.split(',') if x.strip()]\n",
        "OUT_PAGES_DIR = '/content/pages'\n",
        "DETECT_OUT = '/content/grounded_regions'\n",
        "print('PDF:', PLAYBOOK_PDF, 'Pages:', PAGES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb7f44ca",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Logging helpers (GCS)\n",
        "import os, sys, json, time, platform, socket, subprocess\n",
        "from pathlib import Path\n",
        "RUN_ID = time.strftime('%Y%m%d-%H%M%S') + (('-'+RUN_TAG.strip()) if ('RUN_TAG' in globals() and RUN_TAG.strip()) else '')\n",
        "LOCAL_LOG_ROOT = '/content/artifacts/colab_runs' if os.path.exists('/content/artifacts') else '/content/colab_runs'\n",
        "LOG_DIR = Path(LOCAL_LOG_ROOT)/RUN_ID\n",
        "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "def log_json(name, obj):\n",
        "  p = LOG_DIR/name if isinstance(name, Path) else LOG_DIR/str(name)\n",
        "  p.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding='utf-8')\n",
        "def log_kv(key, val):\n",
        "  data = {}\n",
        "  p = LOG_DIR/'run.json'\n",
        "  if p.exists():\n",
        "    try: data = json.loads(p.read_text(encoding='utf-8'))\n",
        "    except Exception: data = {}\n",
        "  data[key]=val\n",
        "  p.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding='utf-8')\n",
        "env = { 'python': sys.version, 'platform': platform.platform(), 'hostname': socket.gethostname(), 'device_req': (DEVICE if 'DEVICE' in globals() else 'auto') }\n",
        "try:\n",
        "  import torch\n",
        "  env.update({'torch': torch.__version__, 'cuda': getattr(torch.version,'cuda',None), 'cuda_available': torch.cuda.is_available()})\n",
        "except Exception: pass\n",
        "log_json('env.json', env)\n",
        "def upload_logs():\n",
        "  if not ('REPORT_TO_GCS' in globals() and REPORT_TO_GCS):\n",
        "    print('[LOG] REPORT_TO_GCS disabled'); return\n",
        "  bucket = (GCS_BUCKET if 'GCS_BUCKET' in globals() else 'pik-artifacts-dev')\n",
        "  prefix = f'colab_runs/{RUN_ID}'\n",
        "  try:\n",
        "    from google.cloud import storage\n",
        "    client=storage.Client()\n",
        "    b=client.bucket(bucket)\n",
        "    for p in LOG_DIR.rglob('*'):\n",
        "      if p.is_file():\n",
        "        rel=str(p.relative_to(LOG_DIR)).replace('\\\\','/')\n",
        "        blob=b.blob(f'{prefix}/{rel}')\n",
        "        ctype='application/json' if p.suffix.lower()=='.json' else 'text/plain; charset=utf-8'\n",
        "        blob.content_type=ctype\n",
        "        blob.upload_from_filename(str(p))\n",
        "    print(f'[LOG] uploaded to gs://{bucket}/{prefix}')\n",
        "    return\n",
        "  except Exception as e:\n",
        "    print('[LOG] storage client failed, fallback to gsutil:', e)\n",
        "  # gsutil fallback\n",
        "  cmd=f\"gsutil -m cp -r '{LOG_DIR}' gs://{bucket}/colab_runs/\"\n",
        "  subprocess.run(['bash','-lc', cmd], check=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d698d22",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Render Pages to PNG\n",
        "# Render selected pages to PNG (robust: checks poppler + PDF presence; falls back to gsutil cp)\n",
        "import os, shutil, pathlib, subprocess\n",
        "from subprocess import check_call\n",
        "pathlib.Path(OUT_PAGES_DIR).mkdir(parents=True, exist_ok=True)\n",
        "# Ensure pdftoppm exists\n",
        "if not shutil.which('pdftoppm'):\n",
        "  print('Installing poppler-utils (pdftoppm)...')\n",
        "  check_call(['bash','-lc','sudo apt-get -q update && sudo apt-get -q install -y poppler-utils'])\n",
        "# Ensure source PDF exists; if not, copy from GCS via gsutil\n",
        "src = PLAYBOOK_PDF\n",
        "if not os.path.exists(src):\n",
        "  print('PDF not found at', src, '; copying from GCS...')\n",
        "  check_call(['bash','-lc','gsutil -m cp \"gs://pik_source_bucket/playbooks/PIK - Expert Guide - Platform IT Architecture - Playbook - v11.pdf\" /content/Playbook.pdf'])\n",
        "  src = '/content/Playbook.pdf'\n",
        "# Render pages\n",
        "for p in PAGES:\n",
        "  print('Rendering', p)\n",
        "  check_call(['pdftoppm','-png','-singlefile','-r','150', src, f'{OUT_PAGES_DIR}/page-{p}'])\n",
        "!ls -la /content/pages | head -n 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4be7c64",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Detection: GroundedDINO → SAM/SAM2\n",
        "# Боевой режим: GroundedDINO → SAM (5 страниц + 3 фрейма)\n",
        "import os, json, pathlib, cv2, numpy as np, torch\n",
        "from groundingdino.util.inference import Model\n",
        "# SAM/SAM2 init with fallback and device control\n",
        "_req = (DEVICE.lower() if 'DEVICE' in globals() else 'auto')\n",
        "if _req == 'cuda' and not torch.cuda.is_available():\n",
        "  print('[warn] CUDA requested but not available; using CPU')\n",
        "  device = 'cpu'\n",
        "elif _req == 'cpu':\n",
        "  device = 'cpu'\n",
        "else:\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Selected device:', device)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "sam2_predictor = None\n",
        "if 'USE_SAM2' in globals() and USE_SAM2:\n",
        "  try:\n",
        "    from sam2.build_sam import build_sam2\n",
        "    from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "    sam2_model = build_sam2('sam2_hiera_large', SAM2_MODEL, device=device)\n",
        "    sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
        "    print('SAM2 ready on', device)\n",
        "  except Exception as e:\n",
        "    print('SAM2 init failed, fallback to SAM v1:', e)\n",
        "    sam2_predictor = None\n",
        "if sam2_predictor is None:\n",
        "  from segment_anything import sam_model_registry, SamPredictor\n",
        "  print('SAM v1 ready on', device)\n",
        "CFG_PATH = '/content/GroundingDINO_SwinT_OGC.py'\n",
        "CFG_URL = 'https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
        "# Попытка скачать конфиг, если его нет\n",
        "import urllib.request, urllib.error\n",
        "def _download(url, path):\n",
        "  try:\n",
        "    urllib.request.urlretrieve(url, path)\n",
        "    return os.path.exists(path) and os.path.getsize(path) > 1000\n",
        "  except Exception:\n",
        "    return False\n",
        "if not os.path.exists(CFG_PATH):\n",
        "  ok = _download(CFG_URL, CFG_PATH)\n",
        "  if not ok:\n",
        "    try:\n",
        "      import groundingdino, os as _os\n",
        "      CFG_PATH = _os.path.join(_os.path.dirname(groundingdino.__file__), 'config', 'GroundingDINO_SwinT_OGC.py')\n",
        "      print('Using package config at', CFG_PATH)\n",
        "    except Exception as e:\n",
        "      raise FileNotFoundError('GroundingDINO config not found and download failed')\n",
        "# Sanity check on DINO checkpoint\n",
        "import torch\n",
        "try:\n",
        "  _ = torch.load(GROUNDING_MODEL, map_location='cpu')\n",
        "except Exception as e:\n",
        "  raise RuntimeError(f'GroundedDINO checkpoint invalid: {e}')\n",
        "gd_model = Model(model_config_path=CFG_PATH, model_checkpoint_path=GROUNDING_MODEL, device=device)\n",
        "def save_region(rdir, idx, img, xyxy):\n",
        "  x0,y0,x1,y1 = map(int, xyxy)\n",
        "  x0,y0 = max(0,x0), max(0,y0)\n",
        "  crop = img[y0:y1, x0:x1] if y1>y0 and x1>x0 else img\n",
        "  ok, buf = cv2.imencode('.png', crop)\n",
        "  if ok: (rdir/f'region-{idx}.png').write_bytes(buf.tobytes())\n",
        "  obj = { 'bbox': {'x':int(x0),'y':int(y0),'w':int(x1-x0),'h':int(y1-y0)}, 'text':'', 'image_b64':'' }\n",
        "  (rdir/f'region-{idx}.json').write_text(json.dumps(obj, ensure_ascii=False), encoding='utf-8')\n",
        "def detect_one(image_path, out_root):\n",
        "  img = cv2.imread(image_path); assert img is not None, image_path\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  H,W = img_rgb.shape[:2]\n",
        "  boxes, logits, phrases = gd_model.predict_with_classes(image=img_rgb, classes=PROMPTS, box_threshold=BOX_THRESHOLD, text_threshold=TEXT_THRESHOLD)\n",
        "  bxs = []\n",
        "  for b in boxes:\n",
        "    b = np.asarray(b, dtype=float)\n",
        "    if b.max()<=1.01: x0,y0,x1,y1 = b[0]*W, b[1]*H, b[2]*W, b[3]*H\n",
        "    else: x0,y0,x1,y1 = b\n",
        "    bxs.append([x0,y0,x1,y1])\n",
        "  out = os.path.join(out_root, pathlib.Path(image_path).stem, 'regions'); ensure_dir(out)\n",
        "  for i,xyxy in enumerate(bxs[:TOPK], start=1): save_region(pathlib.Path(out), i, img, xyxy)\n",
        "# Страницы\n",
        "ensure_dir(DETECT_OUT)\n",
        "for p in PAGES:\n",
        "  detect_one(f'/content/pages/page-{p}.png', DETECT_OUT)\n",
        "# Фреймы\n",
        "for name in FRAME_NAMES:\n",
        "  f = f'/content/src_gcs/frames/{name}'\n",
        "  if os.path.exists(f): detect_one(f, '/content/grounded_frames')\n",
        "# Выгрузка\n",
        "!gsutil -m rsync -r /content/grounded_regions gs://pik-artifacts-dev/grounded_regions/\n",
        "!gsutil -m rsync -r /content/grounded_frames gs://pik-artifacts-dev/grounded_regions/\n",
        "!gsutil ls -r gs://pik-artifacts-dev/grounded_regions | head -n 40\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3538c6",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Upload Regions to GCS\n",
        "# Upload regions to pik-artifacts-dev\n",
        "!gsutil -m rsync -r /content/grounded_regions gs://pik-artifacts-dev/grounded_regions/\n",
        "!gsutil ls gs://pik-artifacts-dev/grounded_regions/ | head -n 20\n",
        "\n",
        "# Upload logs to GCS if enabled\n",
        "try:\n",
        "  if 'upload_logs' in globals(): upload_logs()\n",
        "except Exception as e:\n",
        "  print('[LOG] upload skipped:', e)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}