{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GroundedDINO + SAM — Detection (Colab Pro+)\n",
        "Детектор регионов: монтируем GCS (через сервис‑аккаунт), ставим Torch+детекторы, рендерим страницы, запускаем детекцию и грузим регионы в `gs://pik-artifacts-dev/grounded_regions/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91d7fd2",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Runtime & GPU\n",
        "# Runtime & GPU\n",
        "!nvidia-smi || true\n",
        "import sys; print(sys.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd390ea",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Auth + gcsfuse setup\n",
        "# Install packages and prepare gcsfuse repo; auto-mount with SA from /content/Secrets if present\n",
        "from google.colab import auth; auth.authenticate_user()\n",
        "!pip -q install google-cloud-storage gcsfs\n",
        "!curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\n",
        "!echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt gcsfuse-jammy main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!sudo apt-get -q update\n",
        "!sudo apt-get -q install -y gcsfuse poppler-utils\n",
        "!mkdir -p /content/src_gcs /content/artifacts /content/pages /content/Secrets\n",
        "import glob, os, subprocess, shlex\n",
        "matches = glob.glob('/content/Secrets/*.json')\n",
        "if matches:\n",
        "  KEY = matches[0]\n",
        "  os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = KEY\n",
        "  print('Found SA key:', KEY)\n",
        "  subprocess.run(shlex.split('fusermount -u /content/src_gcs'), check=False)\n",
        "  subprocess.run(shlex.split('fusermount -u /content/artifacts'), check=False)\n",
        "  code1 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik_source_bucket','/content/src_gcs']).returncode\n",
        "  code2 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik-artifacts-dev','/content/artifacts']).returncode\n",
        "  print('mount src=', code1==0, ' mount artifacts=', code2==0)\n",
        "else:\n",
        "  # Ручная загрузка ключа (как раньше)\n",
        "  from google.colab import files\n",
        "  print('Загрузите JSON-ключ сервис-аккаунта (sa.json)')\n",
        "  uploaded = files.upload()\n",
        "  if uploaded:\n",
        "    KEY = '/content/' + list(uploaded.keys())[0]\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = KEY\n",
        "    subprocess.run(shlex.split('fusermount -u /content/src_gcs'), check=False)\n",
        "    subprocess.run(shlex.split('fusermount -u /content/artifacts'), check=False)\n",
        "    c1 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik_source_bucket','/content/src_gcs']).returncode\n",
        "    c2 = subprocess.run(['gcsfuse','--implicit-dirs','--key-file',KEY,'pik-artifacts-dev','/content/artifacts']).returncode\n",
        "    print('mount src=', c1==0, ' mount artifacts=', c2==0)\n",
        "  else:\n",
        "    KEY = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9813e96",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Mount GCS buckets\n",
        "# Mount GCS buckets with SA key\n",
        "KEY_PATH = f'/content/{KEY}'\n",
        "!gcsfuse --implicit-dirs --key-file $KEY_PATH pik_source_bucket /content/src_gcs\n",
        "!gcsfuse --implicit-dirs --key-file $KEY_PATH pik-artifacts-dev /content/artifacts\n",
        "!ls -la /content/src_gcs | head -n 20\n",
        "!echo ok > /content/artifacts/_healthcheck.txt && ls -l /content/artifacts/_healthcheck.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6309994d",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install Torch + SAM/SAM2 + GroundedDINO\n",
        "# 2) Torch + детекторы — надёжная установка (без сборки wheel для GroundedDINO)\n",
        "!pip -q install --upgrade pip setuptools wheel\n",
        "!pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install shapely timm opencv-python pycocotools addict yacs requests pillow\n",
        "!pip -q install huggingface_hub\n",
        "!pip -q install 'jedi>=0.18.2'\n",
        "# SAM\n",
        "!pip -q install git+https://github.com/facebookresearch/segment-anything.git\n",
        "# SAM2\n",
        "!pip -q install git+https://github.com/facebookresearch/segment-anything-2.git\n",
        "# GroundedDINO из исходников (подключим через sys.path)\n",
        "!rm -rf /content/GroundingDINO\n",
        "!git clone --depth 1 https://github.com/IDEA-Research/GroundingDINO.git /content/GroundingDINO\n",
        "!pip -q install -r /content/GroundingDINO/requirements.txt\n",
        "import sys\n",
        "if '/content/GroundingDINO' not in sys.path: sys.path.append('/content/GroundingDINO')\n",
        "from groundingdino.util.inference import Model\n",
        "print('GroundedDINO import OK')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d75b85",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download/Resolve Model Weights\n",
        "#@title Download/Resolve Model Weights\n",
        "# (Optional) Download model weights if not present\n",
        "import os, pathlib, shutil, subprocess\n",
        "from typing import Optional\n",
        "pathlib.Path('/content/models/groundingdino').mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path('/content/models/sam').mkdir(parents=True, exist_ok=True)\n",
        "GROUNDING_MODEL = '/content/models/groundingdino/groundingdino_swint_ogc.pth'\n",
        "SAM_MODEL = '/content/models/sam/sam_vit_h_4b8939.pth'\n",
        "GROUNDING_URL = 'https://github.com/IDEA-Research/GroundingDINO/releases/download/0.1.0/groundingdino_swint_ogc.pth'\n",
        "SAM_URL = 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
        "SAM2_MODEL = '/content/models/sam2/sam2_hiera_large.pt'\n",
        "SAM2_URL = 'https://huggingface.co/facebook/sam2-hiera-large/resolve/main/sam2_hiera_large.pt'\n",
        "# Try to read HF token from Colab Keys or env\n",
        "HF_TOKEN = os.getenv('HF_TOKEN', '')\n",
        "try:\n",
        "  from google.colab import userdata as _ud\n",
        "  HF_TOKEN = _ud.get('HF_TOKEN') or HF_TOKEN\n",
        "except Exception:\n",
        "  pass\n",
        "def _file_ok(p: str, min_size: int) -> bool:\n",
        "  try:\n",
        "    return os.path.exists(p) and os.path.getsize(p) >= min_size\n",
        "  except Exception:\n",
        "    return False\n",
        "def _try_torch_load(p: str) -> bool:\n",
        "  try:\n",
        "    import torch\n",
        "    torch.load(p, map_location='cpu')\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    print('[warn] torch.load failed:', e)\n",
        "    return False\n",
        "def _hf_download(repo_id: str, filename: str, dest: str) -> bool:\n",
        "  try:\n",
        "    from huggingface_hub import hf_hub_download, login\n",
        "    if HF_TOKEN:\n",
        "      try:\n",
        "        login(token=HF_TOKEN)\n",
        "      except Exception as e:\n",
        "        print('[warn] HF login failed:', e)\n",
        "    ckpt = hf_hub_download(repo_id=repo_id, filename=filename, local_dir=os.path.dirname(dest), local_dir_use_symlinks=False, token=HF_TOKEN or None)\n",
        "    if ckpt != dest:\n",
        "      shutil.copy2(ckpt, dest)\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    print('[warn] HF download failed:', e)\n",
        "    return False\n",
        "def _curl(url: str, dest: str, min_size: int) -> bool:\n",
        "  cmd = f\"curl -L --fail --retry 5 --retry-all-errors -o '{dest}.tmp' '{url}'\"\n",
        "  rc = subprocess.call(cmd, shell=True)\n",
        "  if rc == 0 and _file_ok(dest + '.tmp', min_size):\n",
        "    shutil.move(dest + '.tmp', dest)\n",
        "    return True\n",
        "  else:\n",
        "    print('[warn] curl download insufficient or failed:', rc)\n",
        "    try:\n",
        "      os.remove(dest + '.tmp')\n",
        "    except Exception:\n",
        "      pass\n",
        "    return False\n",
        "# GroundedDINO (expect ~0.9GB)\n",
        "MIN_DINO = 600_000_000\n",
        "need_dino = (not _file_ok(GROUNDING_MODEL, MIN_DINO)) or (not _try_torch_load(GROUNDING_MODEL))\n",
        "if need_dino:\n",
        "  print('Downloading GroundingDINO weights (robust)...')\n",
        "  try:\n",
        "    os.remove(GROUNDING_MODEL)\n",
        "  except Exception:\n",
        "    pass\n",
        "  # 1) Try GCS mirror if mounted\n",
        "  gcs_mirror = '/content/artifacts/models/groundingdino/groundingdino_swint_ogc.pth'\n",
        "  ok = _file_ok(gcs_mirror, MIN_DINO)\n",
        "  if ok:\n",
        "    try:\n",
        "      shutil.copy2(gcs_mirror, GROUNDING_MODEL)\n",
        "      ok = True\n",
        "    except Exception as e:\n",
        "      print('[warn] copy from GCS mirror failed:', e); ok = False\n",
        "  # 2) Try HF Hub (public repo)\n",
        "  if (not ok):\n",
        "    ok = _hf_download('ShilongLiu/GroundingDINO', 'groundingdino_swint_ogc.pth', GROUNDING_MODEL)\n",
        "  # 3) Try GitHub release via curl\n",
        "  if (not ok) or (not _file_ok(GROUNDING_MODEL, MIN_DINO)):\n",
        "    ok = _curl(GROUNDING_URL, GROUNDING_MODEL, MIN_DINO)\n",
        "  # 4) Try gsutil from bucket path if accessible\n",
        "  if (not ok) or (not _file_ok(GROUNDING_MODEL, MIN_DINO)):\n",
        "    try:\n",
        "      rc = subprocess.call(f\"gsutil cp gs://pik-artifacts-dev/models/groundingdino/groundingdino_swint_ogc.pth '{GROUNDING_MODEL}'\", shell=True)\n",
        "      ok = (rc == 0) and _file_ok(GROUNDING_MODEL, MIN_DINO)\n",
        "    except Exception as e:\n",
        "      print('[warn] gsutil mirror copy failed:', e)\n",
        "  if (not ok) or (not _file_ok(GROUNDING_MODEL, MIN_DINO)) or (not _try_torch_load(GROUNDING_MODEL)):\n",
        "    raise SystemExit('Failed to fetch a valid GroundingDINO checkpoint')\n",
        "# SAM (ViT-H is large; check size only)\n",
        "MIN_SAM = 1_000_000_000\n",
        "if not _file_ok(SAM_MODEL, MIN_SAM):\n",
        "  print('Downloading SAM ViT-H weights (robust)...')\n",
        "  # 1) Try GCS mirror if mounted\n",
        "  sam_gcs_mirror = '/content/artifacts/models/sam/sam_vit_h_4b8939.pth'\n",
        "  ok = _file_ok(sam_gcs_mirror, MIN_SAM)\n",
        "  if ok:\n",
        "    try:\n",
        "      shutil.copy2(sam_gcs_mirror, SAM_MODEL)\n",
        "      ok = True\n",
        "    except Exception as e:\n",
        "      print('[warn] copy SAM from GCS mirror failed:', e); ok = False\n",
        "  # 2) Try HF Hub\n",
        "  if (not ok):\n",
        "    ok = _hf_download('facebook/sam', 'sam_vit_h_4b8939.pth', SAM_MODEL)\n",
        "  # 3) Try official URL via curl\n",
        "  if (not ok) or (not _file_ok(SAM_MODEL, MIN_SAM)):\n",
        "    ok = _curl(SAM_URL, SAM_MODEL, MIN_SAM)\n",
        "  # 4) Try gsutil mirror from bucket\n",
        "  if (not ok) or (not _file_ok(SAM_MODEL, MIN_SAM)):\n",
        "    try:\n",
        "      rc = subprocess.call(f\"gsutil cp gs://pik-artifacts-dev/models/sam/sam_vit_h_4b8939.pth '{SAM_MODEL}'\", shell=True)\n",
        "      ok = (rc == 0) and _file_ok(SAM_MODEL, MIN_SAM)\n",
        "    except Exception as e:\n",
        "      print('[warn] gsutil SAM mirror copy failed:', e)\n",
        "  if (not ok) or (not _file_ok(SAM_MODEL, MIN_SAM)):\n",
        "    raise SystemExit('Failed to fetch SAM ViT-H checkpoint')\n",
        "# SAM2 (Hiera Large)\n",
        "MIN_SAM2 = 700_000_000\n",
        "if not _file_ok(SAM2_MODEL, MIN_SAM2):\n",
        "  print('Downloading SAM2 Hiera Large weights (robust)...')\n",
        "  # 1) Try GCS mirror if mounted\n",
        "  sam2_gcs_mirror = '/content/artifacts/models/sam2/sam2_hiera_large.pt'\n",
        "  ok = _file_ok(sam2_gcs_mirror, MIN_SAM2)\n",
        "  if ok:\n",
        "    try:\n",
        "      shutil.copy2(sam2_gcs_mirror, SAM2_MODEL)\n",
        "      ok = True\n",
        "    except Exception as e:\n",
        "      print('[warn] copy SAM2 from GCS mirror failed:', e); ok = False\n",
        "  # 2) Try HF Hub\n",
        "  if (not ok):\n",
        "    ok = _hf_download('facebook/sam2-hiera-large', 'sam2_hiera_large.pt', SAM2_MODEL)\n",
        "  # 3) Try direct URL via curl\n",
        "  if (not ok) or (not _file_ok(SAM2_MODEL, MIN_SAM2)):\n",
        "    ok = _curl(SAM2_URL, SAM2_MODEL, MIN_SAM2)\n",
        "  # 4) Try gsutil mirror from bucket\n",
        "  if (not ok) or (not _file_ok(SAM2_MODEL, MIN_SAM2)):\n",
        "    try:\n",
        "      rc = subprocess.call(f\"gsutil cp gs://pik-artifacts-dev/models/sam2/sam2_hiera_large.pt '{SAM2_MODEL}'\", shell=True)\n",
        "      ok = (rc == 0) and _file_ok(SAM2_MODEL, MIN_SAM2)\n",
        "    except Exception as e:\n",
        "      print('[warn] gsutil SAM2 mirror copy failed:', e)\n",
        "  if (not ok) or (not _file_ok(SAM2_MODEL, MIN_SAM2)):\n",
        "    raise SystemExit('Failed to fetch SAM2 Hiera Large checkpoint')\n",
        "print('GROUNDING_MODEL =', GROUNDING_MODEL)\n",
        "print('SAM_MODEL       =', SAM_MODEL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56041eff",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Detection Parameters\n",
        "PLAYBOOK_PDF = '/content/src_gcs/playbooks/PIK - Expert Guide - Platform IT Architecture - Playbook - v11.pdf'  #@param {type:\"string\"}\n",
        "PAGES = [4,5,6,7,8,9,10,11]  #@param {type:\"raw\"}\n",
        "FRAME_NAMES_INPUT = 'PIK - Platform IT Architecture Canvas - Table View - v01.png, PIK - Platform IT Architecture Canvases - v01.png, PIK - Expert Guide - Platform IT Architecture - Assessment - v01.png'  #@param {type:\"string\"}\n",
        "PROMPTS_INPUT = 'diagram,canvas,table,legend,arrow,node'  #@param {type:\"string\"}\n",
        "BOX_THRESHOLD = 0.35  #@param {type:\"number\"}\n",
        "TEXT_THRESHOLD = 0.25  #@param {type:\"number\"}\n",
        "TOPK = 12  #@param {type:\"integer\"}\n",
        "DEVICE = 'auto'  #@param [\"auto\", \"cuda\", \"cpu\"]\n",
        "USE_SAM2 = True  #@param {type:\"boolean\"}\n",
        "# Derived lists from string inputs\n",
        "FRAME_NAMES = [x.strip() for x in FRAME_NAMES_INPUT.split(',') if x.strip()]\n",
        "PROMPTS = [x.strip() for x in PROMPTS_INPUT.split(',') if x.strip()]\n",
        "OUT_PAGES_DIR = '/content/pages'\n",
        "DETECT_OUT = '/content/grounded_regions'\n",
        "print('PDF:', PLAYBOOK_PDF, 'Pages:', PAGES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d698d22",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Render Pages to PNG\n",
        "# Render selected pages to PNG (robust: checks poppler + PDF presence; falls back to gsutil cp)\n",
        "import os, shutil, pathlib, subprocess\n",
        "from subprocess import check_call\n",
        "pathlib.Path(OUT_PAGES_DIR).mkdir(parents=True, exist_ok=True)\n",
        "# Ensure pdftoppm exists\n",
        "if not shutil.which('pdftoppm'):\n",
        "  print('Installing poppler-utils (pdftoppm)...')\n",
        "  check_call(['bash','-lc','sudo apt-get -q update && sudo apt-get -q install -y poppler-utils'])\n",
        "# Ensure source PDF exists; if not, copy from GCS via gsutil\n",
        "src = PLAYBOOK_PDF\n",
        "if not os.path.exists(src):\n",
        "  print('PDF not found at', src, '; copying from GCS...')\n",
        "  check_call(['bash','-lc','gsutil -m cp \"gs://pik_source_bucket/playbooks/PIK - Expert Guide - Platform IT Architecture - Playbook - v11.pdf\" /content/Playbook.pdf'])\n",
        "  src = '/content/Playbook.pdf'\n",
        "# Render pages\n",
        "for p in PAGES:\n",
        "  print('Rendering', p)\n",
        "  check_call(['pdftoppm','-png','-singlefile','-r','150', src, f'{OUT_PAGES_DIR}/page-{p}'])\n",
        "!ls -la /content/pages | head -n 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4be7c64",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Detection: GroundedDINO → SAM/SAM2\n",
        "# Боевой режим: GroundedDINO → SAM (5 страниц + 3 фрейма)\n",
        "import os, json, pathlib, cv2, numpy as np, torch\n",
        "from groundingdino.util.inference import Model\n",
        "# SAM/SAM2 init with fallback and device control\n",
        "_req = (DEVICE.lower() if 'DEVICE' in globals() else 'auto')\n",
        "if _req == 'cuda' and not torch.cuda.is_available():\n",
        "  print('[warn] CUDA requested but not available; using CPU')\n",
        "  device = 'cpu'\n",
        "elif _req == 'cpu':\n",
        "  device = 'cpu'\n",
        "else:\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Selected device:', device)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "sam2_predictor = None\n",
        "if 'USE_SAM2' in globals() and USE_SAM2:\n",
        "  try:\n",
        "    from sam2.build_sam import build_sam2\n",
        "    from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "    sam2_model = build_sam2('sam2_hiera_large', SAM2_MODEL, device=device)\n",
        "    sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
        "    print('SAM2 ready on', device)\n",
        "  except Exception as e:\n",
        "    print('SAM2 init failed, fallback to SAM v1:', e)\n",
        "    sam2_predictor = None\n",
        "if sam2_predictor is None:\n",
        "  from segment_anything import sam_model_registry, SamPredictor\n",
        "  print('SAM v1 ready on', device)\n",
        "CFG_PATH = '/content/GroundingDINO_SwinT_OGC.py'\n",
        "CFG_URL = 'https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
        "# Попытка скачать конфиг, если его нет\n",
        "import urllib.request, urllib.error\n",
        "def _download(url, path):\n",
        "  try:\n",
        "    urllib.request.urlretrieve(url, path)\n",
        "    return os.path.exists(path) and os.path.getsize(path) > 1000\n",
        "  except Exception:\n",
        "    return False\n",
        "if not os.path.exists(CFG_PATH):\n",
        "  ok = _download(CFG_URL, CFG_PATH)\n",
        "  if not ok:\n",
        "    try:\n",
        "      import groundingdino, os as _os\n",
        "      CFG_PATH = _os.path.join(_os.path.dirname(groundingdino.__file__), 'config', 'GroundingDINO_SwinT_OGC.py')\n",
        "      print('Using package config at', CFG_PATH)\n",
        "    except Exception as e:\n",
        "      raise FileNotFoundError('GroundingDINO config not found and download failed')\n",
        "# Sanity check on DINO checkpoint\n",
        "import torch\n",
        "try:\n",
        "  _ = torch.load(GROUNDING_MODEL, map_location='cpu')\n",
        "except Exception as e:\n",
        "  raise RuntimeError(f'GroundedDINO checkpoint invalid: {e}')\n",
        "gd_model = Model(model_config_path=CFG_PATH, model_checkpoint_path=GROUNDING_MODEL, device=device)\n",
        "def save_region(rdir, idx, img, xyxy):\n",
        "  x0,y0,x1,y1 = map(int, xyxy)\n",
        "  x0,y0 = max(0,x0), max(0,y0)\n",
        "  crop = img[y0:y1, x0:x1] if y1>y0 and x1>x0 else img\n",
        "  ok, buf = cv2.imencode('.png', crop)\n",
        "  if ok: (rdir/f'region-{idx}.png').write_bytes(buf.tobytes())\n",
        "  obj = { 'bbox': {'x':int(x0),'y':int(y0),'w':int(x1-x0),'h':int(y1-y0)}, 'text':'', 'image_b64':'' }\n",
        "  (rdir/f'region-{idx}.json').write_text(json.dumps(obj, ensure_ascii=False), encoding='utf-8')\n",
        "def detect_one(image_path, out_root):\n",
        "  img = cv2.imread(image_path); assert img is not None, image_path\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  H,W = img_rgb.shape[:2]\n",
        "  boxes, logits, phrases = gd_model.predict_with_classes(image=img_rgb, classes=PROMPTS, box_threshold=BOX_THRESHOLD, text_threshold=TEXT_THRESHOLD)\n",
        "  bxs = []\n",
        "  for b in boxes:\n",
        "    b = np.asarray(b, dtype=float)\n",
        "    if b.max()<=1.01: x0,y0,x1,y1 = b[0]*W, b[1]*H, b[2]*W, b[3]*H\n",
        "    else: x0,y0,x1,y1 = b\n",
        "    bxs.append([x0,y0,x1,y1])\n",
        "  out = os.path.join(out_root, pathlib.Path(image_path).stem, 'regions'); ensure_dir(out)\n",
        "  for i,xyxy in enumerate(bxs[:TOPK], start=1): save_region(pathlib.Path(out), i, img, xyxy)\n",
        "# Страницы\n",
        "ensure_dir(DETECT_OUT)\n",
        "for p in PAGES:\n",
        "  detect_one(f'/content/pages/page-{p}.png', DETECT_OUT)\n",
        "# Фреймы\n",
        "for name in FRAME_NAMES:\n",
        "  f = f'/content/src_gcs/frames/{name}'\n",
        "  if os.path.exists(f): detect_one(f, '/content/grounded_frames')\n",
        "# Выгрузка\n",
        "!gsutil -m rsync -r /content/grounded_regions gs://pik-artifacts-dev/grounded_regions/\n",
        "!gsutil -m rsync -r /content/grounded_frames gs://pik-artifacts-dev/grounded_regions/\n",
        "!gsutil ls -r gs://pik-artifacts-dev/grounded_regions | head -n 40\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3538c6",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Upload Regions to GCS\n",
        "# Upload regions to pik-artifacts-dev\n",
        "!gsutil -m rsync -r /content/grounded_regions gs://pik-artifacts-dev/grounded_regions/\n",
        "!gsutil ls gs://pik-artifacts-dev/grounded_regions/ | head -n 20\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}