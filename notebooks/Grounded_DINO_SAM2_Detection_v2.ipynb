{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroundedDINO + SAM2 — Чистый пайплайн\n",
    "\n",
    "Минимальный, воспроизводимый ноутбук для извлечения регионов (CV или GroundedDINO+SAM2), анализа LLM, инжеста фактов и генерации обзора/метрик.\n",
    "\n",
    "- Без тяжёлых инсталлов по умолчанию — опционально через %pip.\n",
    "- Идемпотентные ячейки: безопасно перезапускать.\n",
    "- Концентрируемся на вызове готовых CLI из `scripts/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["parameters"]
   },
   "outputs": [],
   "source": [
    "# Конфиг (правьте под себя)\n",
    "MODEL_DIR = '/root/models'                    # где лежат веса\n",
    "PDF_PATH  = '/root/data/playbook.pdf'        # исходный PDF (можно локальный путь или GCS загрузить ниже)\n",
    "JSON_PATH = '/root/data/playbook.json'       # связанный Unstructured JSON для инжеста\n",
    "PAGES     = [42, 45]                         # список страниц для прогонов\n",
    "OUT_PAGES = "out/page_images/PIK - Expert Guide - Platform IT Architecture - Playbook - v11"\n",
    "OUT_DET   = 'out/visual/grounded_regions'    # целевой каталог для детекции (или cv_regions)\n",
    "USE_CV    = True                             # True: быстрый CV, False: GroundedDINO+SAM2\n",
    "CHAT_MODEL = 'gpt-4o'                         # анализ регионов\n",
    "EMB_MODEL  = 'text-embedding-3-large'         # эмбеддинги\n",
    "INDEX_PATH = 'out/openai_embeddings.ndjson'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка окружения\n",
    "GPU, версии библиотек и доступность ключей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, json, subprocess, sys\n",
    "from pathlib import Path\n",
    "\n",
    "def sh(cmd, check=True):\n",
    "    print('→', cmd)\n",
    "    res = subprocess.run(cmd, shell=True, text=True)\n",
    "    if check and res.returncode != 0:\n",
    "        raise SystemExit(f'Command failed: {cmd}')\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print('torch', torch.__version__, 'cuda', torch.cuda.is_available())\n",
    "except Exception as e:\n",
    "    print('torch import error:', e)\n",
    "\n",
    "print('OPENAI_API_KEY set:', bool(os.getenv('OPENAI_API_KEY')))\n",
    "print('MODEL_DIR exists:', Path(MODEL_DIR).exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Опционально) Загрузка из GCS\n",
    "Для загрузки нужны `google-cloud-storage` и `GOOGLE_APPLICATION_CREDENTIALS`. Пропустите, если файлы уже на диске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install -q google-cloud-storage || true\n",
    "\n",
    "if False:  # ← включите при необходимости\n",
    "    from google.cloud import storage\n",
    "    cli = storage.Client()\n",
    "    jobs = [\n",
    "        ('pik_source_bucket','playbooks/PIK - Expert Guide - Platform IT Architecture - Playbook - v11.pdf', PDF_PATH),\n",
    "        ('pik_result_bucket','Qdrant_Destination/playbooks/PIK - Expert Guide - Platform IT Architecture - Playbook - v11.pdf.json', JSON_PATH),\n",
    "    ]\n",
    "    for bkt,obj,dst in jobs:\n",
    "        Path(dst).parent.mkdir(parents=True, exist_ok=True)\n",
    "        cli.bucket(bkt).blob(obj).download_to_filename(dst)\n",
    "        print('downloaded:', dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рендер страниц PDF → PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(OUT_PAGES).mkdir(parents=True, exist_ok=True)\n",
    "pages_str = ' '.join(str(p) for p in PAGES)\n",
    "cmd = f\"python scripts/render_pages.py --pdf \"{PDF_PATH}\" --pages {pages_str} --outdir \"{OUT_PAGES}\" --dpi 150\"\n",
    "sh(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Детекция регионов\n",
    "- CV (быстро, без весов) — `scripts/cv_segment.py`\n",
    "- GroundedDINO+SAM2 (точнее, требует веса) — `scripts/grounded_sam_detect.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [str(Path(OUT_PAGES)/f'page-{p}.png') for p in PAGES]\n",
    "if USE_CV:\n",
    "    Path('out/visual/cv_regions').mkdir(parents=True, exist_ok=True)\n",
    "    pages_str = ' '.join(str(p) for p in PAGES)\n",
    "    cmd = f\"python scripts/cv_segment.py --images-dir \"{OUT_PAGES}\" --pages {pages_str} --outdir out/visual/cv_regions\"\n",
    "    OUT_DET = 'out/visual/cv_regions'\n",
    "    sh(cmd)\n",
    "else:\n",
    "    Path(OUT_DET).mkdir(parents=True, exist_ok=True)\n",
    "    prom = 'diagram canvas table legend node arrow'\n",
    "    images = ' '.join(f\"\\\"{i}\\\"\" for i in imgs)\n",
    "    cmd = f\"python scripts/grounded_sam_detect.py --images {images} --outdir {OUT_DET} --prompts {prom}\"\n",
    "    sh(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ регионов LLM → артефакты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"python scripts/analyze_detected_regions.py --detected-dir {OUT_DET} --all --outdir {OUT_DET} --chat-model {CHAT_MODEL} --skip-existing\"\n",
    "sh(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инжест фактов в индекс и обзор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"python scripts/ingest_visual_artifacts.py --source-json \"{JSON_PATH}\" --regions-dir {OUT_DET} --out {INDEX_PATH} --model {EMB_MODEL}\"\n",
    "sh(cmd)\n",
    "sh('python scripts/generate_visual_review.py --inline')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики (опционально)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh(f'python scripts/eval_metrics.py --index {INDEX_PATH} --eval eval/queries.jsonl --prefer-visual')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регистрация ядра (один раз, опционально)\n",
    "Позволяет выбирать ядро по имени в VSCode/Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните один раз при необходимости:\n",
    "# %pip install -q ipykernel\n",
    "# import sys, subprocess\n",
    "# subprocess.run([sys.executable, '-m', 'ipykernel', 'install', '--user', '--name', 'aipi_v2', '--display-name', 'Python (AiPIK v2)'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

