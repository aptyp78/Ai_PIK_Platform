# PIKAi — Execution Roadmap (2025‑09‑16)

This roadmap builds on the current Multimodal RAG stack and the GroundedDINO/SAM visual pipeline status. It prioritizes reliability, retrieval quality, and a usable query/answer API.

## Milestone A (1–2 weeks): Stabilize Visual → Index Loop
- Grounded SAM2: finalize config in `scripts/grounded_sam_pipeline.py`, add env‑based model paths (`$MODEL_DIR/{groundingdino,sam,sam2}`), and graceful fallback to SAM v1 if SAM2 init fails.
- Caching & idempotency: ensure `scripts/analyze_detected_regions.py` and `scripts/ingest_visual_artifacts.py` skip existing artifacts (`--skip-existing` / checksum) to cut token/time.
- Artifact versioning: write a small JSON manifest per unit (pages/regions) with hashes and timestamps; publish to GCS next to artifacts for traceability.
- Weight mirroring: mirror GroundedDINO/SAM weights to `gs://pik-artifacts-dev/models/...`; update Colab to read from GCS to avoid flaky downloads.
- Eval hygiene: expand `eval/queries.jsonl` to ±60 items, re‑baseline metrics with type/tag weights and prefer‑visual on; auto‑write a daily snapshot to `eval/review.md`.

- Methodology coverage (add): index all Unstructured JSON across PIK sources (not only IT playbook). Add a one‑shot indexer over `pik_source_bucket/{playbooks,frames,vlm_unstructured,raw_json}` to include the broader methodology content (PIK 5‑0, frameworks, canvases).

Deliverables:
- Reliable E2E script `scripts/pull_grounded_ingest_eval.sh` runs green; `eval/visual_review.html` refreshed.
- Updated `out/openai_embeddings.ndjson` with new VisualCaption/VisualFact items.

## Milestone B (1–2 weeks): Retrieval Quality Boost
- Hybrid retrieval (image): add CLIP/OpenCLIP embeddings for region/page PNGs; write `scripts/embed_images.py` and extend `scripts/retrieval_search.py` to blend CLIP cosine with text score (weighted sum).
- LLM reranker: optional rescoring of top‑30 via a compact prompt (faithfulness + topicality). Plumb a `--rerank` flag into `scripts/eval_metrics.py` for A/B comparisons.
- Tag normalization: enrich `*.struct.json` → controlled tags (Pillar, Layer, Canvas, Assessment, Diagram) and persist in `meta.tags` to enable consistent tag boosts.

Deliverables:
- Image vectors stored alongside text; blended retrieval path; improved recall@1/MRR.

## Milestone C (1–2 weeks): Qdrant Integration + Lightweight API
- Qdrant upsert: add `scripts/qdrant_push.py` to create/update a collection and upload vectors with metadata. Config via `$QDRANT_URL`, `$QDRANT_API_KEY`, `$QDRANT_COLLECTION`.
- Qdrant search CLI: add `scripts/qdrant_search.py` parity with type/tag weights; ensure filters (e.g., `type in ['VisualFact','Text']`, `tags contains 'Pillar'`).
- Minimal API: FastAPI service `api/app.py` with `/search` and `/answer` endpoints; load from Qdrant (preferred) or NDJSON fallback.

Deliverables:
- Runnable service (uvicorn) that answers and cites sources (file/page/region).

## Milestone D (2–3 weeks): Graph Layer and Assisted Authoring
- Graph build: transform `*.struct.json` into a NetworkX graph; export GEXF and a compact summary (`graph/summary.md`).
- Graph‑aware retrieval: optional pre‑filter (e.g., restrict to `Pillar=Security`) and context enrichment from 1‑hop neighbors.
- Assisted authoring: simple script to synthesize draft “assessment” answers from graph + facts for human review.

Deliverables:
- `scripts/build_graph.py`, `scripts/graph_filter_search.py`, and GEXF export for exploration.

## Engineering Quality & Ops
- Orchestration: parameterize the pipeline for Prefect (1 flow with tasks: sync → analyze → ingest → evaluate). Keep shell as local runner; add Prefect later for scheduling.
- Secrets & spend controls: centralize API keys in `.env`, add token‑use counters to LLM analyze step; fail safe when budget exceeded.
- Monitoring: write a slim log summary after every run (counts, error rates, avg sim of top‑1) and ship to a CSV/JSONL for trend charts.

Notebook Reliability (Colab) — addendum
- Disable gating and run full volume: in Colab notebook remove the execution gate (Control & Parameters). Keep defaults to “all pages” and run end‑to‑end without START_RUN toggles.
- Fix Torch + SAM/SAM2 + GroundedDINO install cell: consistent pins, optional xformers, add multi‑mirror weights fetch (HF Hub + GCS mirror + curl fallback).
- Provide a patcher utility to normalize the notebook (already included) and a CI check to validate JSON structure.

## Immediate Next Actions (this week)
1) Full methodology index: run `scripts/rebuild_index_all.py` to index all Unstructured JSON under PIK sources; refresh suggestions and positives for evaluation.
2) Fix Colab notebook reliability: disable control gate; ensure Torch/SAM/SAM2/GroundedDINO install succeeds; commit patched notebook.
3) Visual: ensure manifests + idempotency and re‑ingest; CLIP embeddings for regions and pages.
4) Proceed to Qdrant push and API.

Notes
- The current stack is strong: NDJSON embeddings, adjustable type/tag weights, and visual facts already move metrics. The biggest step‑ups now are (a) robust artifact loop, (b) image‑aware retrieval, and (c) a small API for consumption.
